---
layout: post
title: DeepsvFilter:基于深度学习完成结果变异过滤
date: 2025-03-16 17:11
tags: [paper,SV]
toc: true
---


最近在做基因组结构变异相关工作，阅读相关论文，这篇论文就是关于基因组结构变异的，主要用于从寻找出的结构变异中去除假阳性结果，获取真实结构变异。


## Introduction 
---
发表期刊：Briefings in Bioinformatics
发表时间：2021年
作者：Yongzhuang liu等
原文链接：[A deep learning approach for filtering structural variants in short read sequencing data](https://doi.org/10.1093/bib/bbaa370)

摘要

> 随着基因组测序数据的成本下降、越来越多的测序数据用于基因组研究包括基因组结构变异研究，在人类基因组中广泛应用，但是由于二代重测序数据的局限性，假阳性的结果很多，所以需要合适的变异过滤措施来保证变异的准确性。




## 研究背景
---


1. 二代测序的固有缺点导致结构变异检测结果中假阳性数量居高不下
2. 过滤假阳性变异的参数难以指定，不同数据集有不同的特征，所以每个数据集的过滤参数难以指定
3. 手动将bam文件可视化并查看结构变异区域bam文件支持度的方式效率太低，并且全基因组范围一般有成千上万个结构变异，手动查看比对文件太慢
4. 监督学习方法已经广泛应用于检测基因组或外显子变异，多数工具都将该类任务转换成分类任务，使用神经网络来解决

- 作者列举了一些使用深度学习来解决基因组变异问题的例子

|        软件         |                          解决问题                           |
| :---------------: | :-----------------------------------------------------: |
|    forestSV,SV    |            使用read alignment通过随机森林和支持向量机检测SV             |
|    DeepVariant    | 使用read alignment 通过将比对和相关信息encode成图片使用神经网络检测Indels,SNVs |
| CNNScore Variants |                    使用神经网络过滤SNP,INDEL                    |
|    Clairvoyant    |                 将SNVs和INDELs的检测转化成多分类任务                 |


## 核心问题提取
---
从简介中可以了解到，此文章重点在于基因组结构变异的过滤，通过对背景以及简介部分的精炼大概可以提取出以下关键问题

1. 怎么将SVs的过滤转换成分类问题？

2. 怎么获取高质量的训练数据？

3. 怎么将变异数据编码成适合神经网络训练的数据？

4. 选用什么样的模型？


## 思路方法

---

作者仅考虑100bp以上的结构变异，因为50～100bp的变异对于二代测序数据来说，还是能准确的检测出来的。并且其选择将不同的变异类型分开，这样做也有一定道理，不同变异类型肯定有不同的特征，分开来提取特征或许更好，如果一起来提取那么获取到的特征可能没那么准确。

### 数据准备

-  训练数据的获取

该研究使用GIAB的HG002样本的60X WGS数据（已经使用NovoAlign 比对到hs37d5）以及 NA12878 （50X） 作为训练数据，其使用Lumpy,Delly,Manta分别对该样本检测结构变异（排除着丝粒和中心粒区域），如果使用这三种工具找到的结构变异与GIAB中的某个变异有90%以上的重叠，那么就列为Positive样本，否则列为Negative样本，随后将每个SV断点编码成一张3通道的图片，具体方法后述，将这些标记图片的90%用于训练，10%用于验证。


- 预测数据

与准备训练数据一致，使用三种不同的工具检测变异，对于DELs,DUPs,INVs,如果三个工具的结果中有90%以上的相互重叠那么当成一个变异，对于INS，如果三个结果中某一个INS他们的断点在上下游100bp内，那么当成同一个变异，然后生成SV image，交给训练好的模型进行预测。




- SV图片生成

对于非INS类型变异，其将两个断点扩展成两个范围 ： $[x-\alpha , x+\alpha]$ , $[y - \alpha,y + \alpha]$ , 其中 $\alpha$ 是模型超参数下，对于不同的模型，设置为149或者112；对于INS类型变异，因为只有一个“断点”，那么只对该点进行上述操作。


对于每个断点，提取上述范围内的RD（Read depth）,SR（Split Reads）,DRP（discordant reads pairs）的信息形成三个通道，并且限制每个位点覆盖的reads数目不超过149,112,那么每个图片的形状为 $299 * 149$ 或者 $224 * 112$。 这个形状怎么来的呢，即以断点为中心，上下游指定范围内，覆盖这个范围的reads的三种信息将会被编码，每行对应一个reads。

针对RD通道，如果位点被某reads覆盖，那么该像素填充为255，如果没被覆盖则填充0

针对SR通道，如果该位点在某个Reads发生split read，那么填充为255，反之为0

针对DRP通道，如果该位点的reads被标记为discordant那么填充255，反之为0（该研究对discordant有具体描述，见原文Method部分）



如果一个断点的范围覆盖了配对的另一个断点，那么对这两个断点仍然生成两张图像。忽略掉左断点中覆盖了右断点的SRs和DRPs，同理右断点忽略左断点的SRs和DRPs。最后将DRPs和SRs信息放在图像顶部 ？（疑惑中……）


完成一个SV的两张图片的生成后，在垂直方向上将两张图concat起来，形成一张，表示该SV。




- 数据增强

作者对typical true sv(样本中左右断点的距离和ground truth set中左右断点的距离不超过158bp) ， Typical false sv(与前者相反，超过了158bp)进行数据增强（水平翻转，垂直翻转）以扩展训练数据集。




真正准备训练数据时，只准备了DEL,DUP类型数据，并且分开准备的，DEL类型直接使用上述方法，取工具与GIAB中重合的部分，但是DUP类型，直接使用两个工具都得出的相同位点为POSTIVE SV（个人绝对不妥，但是迫于没有ground truth data）



最后90%的图片用于训练，10%的图片用于训练时验证。



### 模型选择与训练

该研究使用迁移学习，使用Inception-ResNet V2 , MobileNet v1 , NASNet-A Mobile , PNASNet-5 Mobile模型，每个batch为16张SV图片，训练轮数为13轮，动态调整学习率。










PS: 本文只用作学习笔记，我更多关注数据以及方法部分，后续作者对各个模型的结果进行了比较，如有兴趣请查看原文。




参考


[A deep learning approach for filtering structural variants in short read sequencing data](https://doi.org/10.1093/bib/bbaa370)